{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "zombie_detection.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rOvvWAVTkMR7"
      },
      "source": [
        "# zombie detection\n",
        "\n",
        "<img src='https://drive.google.com/uc?export=view&id=18Ck0qNSZy9F1KsUKWc4Jv7_x_1e_fXTN' alt='zombie'>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPs64QA1Zdov"
      },
      "source": [
        "## installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oi28cqGGFWnY"
      },
      "source": [
        "!rm -rf ./models/\n",
        "!git clone --depth 1 https://github.com/tensorflow/models/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwdsBdGhFanc"
      },
      "source": [
        "!cd models/research/ && protoc object_detection/protos/*.proto --python_out=."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yWhz5fQzqSb"
      },
      "source": [
        "%%writefile models/research/setup.py\n",
        "\n",
        "import os\n",
        "from setuptools import find_packages\n",
        "from setuptools import setup\n",
        "\n",
        "REQUIRED_PACKAGES = [\n",
        "    'tf-models-official==2.8.0',\n",
        "    'tensorflow_io'\n",
        "]\n",
        "\n",
        "setup(\n",
        "    name='object_detection',\n",
        "    version='0.1',\n",
        "    install_requires=REQUIRED_PACKAGES,\n",
        "    include_package_data=True,\n",
        "    packages=(\n",
        "        [p for p in find_packages() if p.startswith('object_detection')] +\n",
        "        find_packages(where=os.path.join('.', 'slim'))),\n",
        "    package_dir={\n",
        "        'datasets': os.path.join('slim', 'datasets'),\n",
        "        'nets': os.path.join('slim', 'nets'),\n",
        "        'preprocessing': os.path.join('slim', 'preprocessing'),\n",
        "        'deployment': os.path.join('slim', 'deployment'),\n",
        "        'scripts': os.path.join('slim', 'scripts'),\n",
        "    },\n",
        "    description='Tensorflow Object Detection Library',\n",
        "    python_requires='>3.6',\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aq1-SiyB0YTP"
      },
      "source": [
        "!python -m pip install models/research"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21tUtyyVrkIt"
      },
      "source": [
        "## imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZcqD4NLdnf4"
      },
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "import random\n",
        "import zipfile\n",
        "import io\n",
        "import scipy.misc\n",
        "import numpy as np\n",
        "\n",
        "import glob\n",
        "import imageio\n",
        "from six import BytesIO\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from IPython.display import display, Javascript\n",
        "from IPython.display import Image as IPyImage\n",
        "\n",
        "try:\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.get_logger().setLevel('ERROR')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YihOFxxrkIw"
      },
      "source": [
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "from object_detection.utils import label_map_util, config_util, colab_utils, visualization_utils as viz_utils\n",
        "from object_detection.builders import model_builder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IogyryF2lFBL"
      },
      "source": [
        "## utilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-y9R0Xllefec"
      },
      "source": [
        "def load_image_into_numpy_array(path):    \n",
        "    img_data = tf.io.gfile.GFile(path, 'rb').read()\n",
        "    image = Image.open(BytesIO(img_data))\n",
        "    (im_width, im_height) = image.size\n",
        "    \n",
        "    return np.array(image.getdata()).reshape(\n",
        "        (im_height, im_width, 3)).astype(np.uint8)\n",
        "\n",
        "\n",
        "def plot_detections(image_np,\n",
        "                    boxes,\n",
        "                    classes,\n",
        "                    scores,\n",
        "                    category_index,\n",
        "                    figsize=(12, 16),\n",
        "                    image_name=None):\n",
        "    image_np_with_annotations = image_np.copy()\n",
        "    \n",
        "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "        image_np_with_annotations,\n",
        "        boxes,\n",
        "        classes,\n",
        "        scores,\n",
        "        category_index,\n",
        "        use_normalized_coordinates=True,\n",
        "        min_score_thresh=0.8)\n",
        "    \n",
        "    if image_name:\n",
        "        plt.imsave(image_name, image_np_with_annotations)\n",
        "    \n",
        "    else:\n",
        "        plt.imshow(image_np_with_annotations)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSaXL28TZfk1"
      },
      "source": [
        "## download the zombie data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqSFoJz2Cgzs"
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/training-zombie.zip \\\n",
        "    -O ./training-zombie.zip\n",
        "\n",
        "local_zip = './training-zombie.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('./training')\n",
        "zip_ref.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HyzSGUDsrkI7"
      },
      "source": [
        "### visualize the training images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQy3ND7EpFQM"
      },
      "source": [
        "%matplotlib inline\n",
        "train_image_dir = 'training'\n",
        "train_images_np = []\n",
        "for i in range(1, 6):\n",
        "    image_path = os.path.join(f\"{os.getcwd()}/{train_image_dir}/training-zombie{i}.jpg\")\n",
        "    image = Image.open(image_path)\n",
        "    train_images_np.append(np.array(image))\n",
        "\n",
        "plt.rcParams['axes.grid'] = False\n",
        "plt.rcParams['xtick.labelsize'] = False\n",
        "plt.rcParams['ytick.labelsize'] = False\n",
        "plt.rcParams['xtick.top'] = False\n",
        "plt.rcParams['xtick.bottom'] = False\n",
        "plt.rcParams['ytick.left'] = False\n",
        "plt.rcParams['ytick.right'] = False\n",
        "plt.rcParams['figure.figsize'] = [14, 7]\n",
        "\n",
        "for idx, train_image_np in enumerate(train_images_np):\n",
        "    plt.subplot(1, 5, idx+1)\n",
        "    plt.imshow(train_image_np)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dqb_yjAo3cO_"
      },
      "source": [
        "## prepare data for training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDJadmvdrkI_"
      },
      "source": [
        "ref_gt_boxes = [\n",
        "        np.array([[0.27333333, 0.41500586, 0.74333333, 0.57678781]]),\n",
        "        np.array([[0.29833333, 0.45955451, 0.75666667, 0.61078546]]),\n",
        "        np.array([[0.40833333, 0.18288394, 0.945, 0.34818288]]),\n",
        "        np.array([[0.16166667, 0.61899179, 0.8, 0.91910903]]),\n",
        "        np.array([[0.28833333, 0.12543962, 0.835, 0.35052755]]),\n",
        "      ]\n",
        "\n",
        "gt_boxes = ref_gt_boxes\n",
        "for gt_box in gt_boxes:\n",
        "    try:\n",
        "      assert(gt_box is not None)\n",
        "    \n",
        "    except:\n",
        "      gt_boxes = ref_gt_boxes\n",
        "      break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olhzhCH5heJa"
      },
      "source": [
        "#### view ground truth box coordinates"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxd66yq-M9Va"
      },
      "source": [
        "for gt_box in gt_boxes:\n",
        "  print(gt_box)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVeDQaSdrkJC"
      },
      "source": [
        "### define the category index dictionary\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWBqFVMcweF-"
      },
      "source": [
        "zombie_class_id = 1\n",
        "category_index = {zombie_class_id: {'id': zombie_class_id, 'name': 'zombie'}}\n",
        "num_classes = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPy7vfCCrkJF"
      },
      "source": [
        "print(category_index[zombie_class_id])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTvj7Q0oYk75"
      },
      "source": [
        "### data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H68ot6BkrkJH"
      },
      "source": [
        "label_id_offset = 1\n",
        "train_image_tensors = []\n",
        "gt_classes_one_hot_tensors = []\n",
        "gt_box_tensors = []\n",
        "\n",
        "for (train_image_np, gt_box_np) in zip(train_images_np, gt_boxes):\n",
        "    train_image_tensors.append(tf.expand_dims(tf.convert_to_tensor(\n",
        "        train_image_np, dtype=tf.float32), axis=0))\n",
        "    \n",
        "    gt_box_tensors.append(tf.convert_to_tensor(gt_box_np, dtype=tf.float32))\n",
        "    \n",
        "    zero_indexed_groundtruth_classes = tf.convert_to_tensor(\n",
        "        np.ones(shape=[gt_box_np.shape[0]], dtype=np.int32) - label_id_offset)\n",
        "    \n",
        "    gt_classes_one_hot_tensors.append(tf.one_hot(\n",
        "        zero_indexed_groundtruth_classes, num_classes))\n",
        "\n",
        "print('Done prepping data.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3_Z3mJWN9KJ"
      },
      "source": [
        "## visualize the zombies with their ground truth bounding boxes\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBD6l-E4N71y"
      },
      "source": [
        "dummy_scores = np.array([1.0], dtype=np.float32)\n",
        "plt.figure(figsize=(30, 15))\n",
        "for idx in range(5):\n",
        "    plt.subplot(2, 4, idx+1)\n",
        "    plot_detections(\n",
        "      train_images_np[idx],\n",
        "      gt_boxes[idx],\n",
        "      np.ones(shape=[gt_boxes[idx].shape[0]], dtype=np.int32),\n",
        "      dummy_scores, category_index)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghDAsqfoZvPh"
      },
      "source": [
        "## download the checkpoint containing the pre-trained weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9J16r3NChD-7"
      },
      "source": [
        "!wget http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz\n",
        "!tar -xf ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz\n",
        "!mv ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/checkpoint models/research/object_detection/test_data/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgG_YT7UrkJQ"
      },
      "source": [
        "## configure the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59sEM6wXheJa"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "pipeline_config = \"/content/models/research/object_detection/configs/tf2/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.config\"\n",
        "configs = config_util.get_configs_from_pipeline_file(pipeline_config)\n",
        "configs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ps3AzqBvheJa"
      },
      "source": [
        "model_config = configs['model']\n",
        "model_config"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxHqQK1eheJa"
      },
      "source": [
        "### modify model config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RyT4BUbaMeG-"
      },
      "source": [
        "model_config.ssd.num_classes = num_classes\n",
        "model_config.ssd.freeze_batchnorm = True\n",
        "model_config"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFnuT2rfheJa"
      },
      "source": [
        "## build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfoRTeV_rkJT"
      },
      "source": [
        "detection_model = model_builder.build(model_config, is_training=True)\n",
        "print(type(detection_model))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2C97Zo0OJnOf"
      },
      "source": [
        "## restore weights from checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M81_BgsuheJa"
      },
      "source": [
        "detection_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfxROGsrheJa"
      },
      "source": [
        "#### find the source code for detection_model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6McB9xTheJa"
      },
      "source": [
        "vars(detection_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToM0KgeMheJa"
      },
      "source": [
        "detection_model._box_predictor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Od3eQek-heJa"
      },
      "source": [
        "vars(detection_model._box_predictor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BK06DyFheJa"
      },
      "source": [
        "### define checkpoints for the box predictor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KPWWYbyrkJY"
      },
      "source": [
        "tmp_box_predictor_checkpoint = tf.train.Checkpoint(_box_predictor=detection_model._box_predictor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZlefNC_XheJa"
      },
      "source": [
        "type(tmp_box_predictor_checkpoint)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9X0BfufheJa"
      },
      "source": [
        "vars(tmp_box_predictor_checkpoint)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqMyPTU1rkJa"
      },
      "source": [
        "### define the temporary model checkpoint\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCqGfrawrkJa"
      },
      "source": [
        "tmp_model_checkpoint = tf.train.Checkpoint(_box_predictor=tmp_box_predictor_checkpoint, _feature_extractor=detection_model._feature_extractor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QXZBgRtheJa"
      },
      "source": [
        "type(tmp_model_checkpoint)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSxZqzU4heJa"
      },
      "source": [
        "vars(tmp_model_checkpoint)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_BtL4ZZKVvV"
      },
      "source": [
        "### restore the checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elkvDUUarkJg"
      },
      "source": [
        "checkpoint_path = \"/content/models/research/object_detection/test_data/checkpoint/ckpt-0\"\n",
        "checkpoint = tf.train.Checkpoint(model=tmp_model_checkpoint)\n",
        "checkpoint.restore(checkpoint_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0k6oFoxTrkJi"
      },
      "source": [
        "### run a dummy image to generate the model variables"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dummy = tf.zeros((4, 640, 640, 3))"
      ],
      "metadata": {
        "id": "oA2UWoyEo6wD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MANTSP9LrkJi"
      },
      "source": [
        "tmp_image, tmp_shapes = detection_model.preprocess(dummy)\n",
        "tmp_prediction_dict = detection_model.predict(tmp_image, tmp_shapes)\n",
        "tmp_detections = detection_model.postprocess(tmp_prediction_dict, tmp_shapes)\n",
        "print('Weights restored!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0KvPP-krkJn"
      },
      "source": [
        "assert len(detection_model.trainable_variables) > 0, \"Please pass in a dummy image to create the trainable variables.\"\n",
        "print(detection_model.weights[0].shape)\n",
        "print(detection_model.weights[231].shape)\n",
        "print(detection_model.weights[462].shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "njlV4PoPrkJq"
      },
      "source": [
        "### set training hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyHoF4mUrv5-"
      },
      "source": [
        "tf.keras.backend.set_learning_phase(True)\n",
        "batch_size = 4\n",
        "num_batches = 100\n",
        "learning_rate = .01\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-MaJmHmrkJs"
      },
      "source": [
        "## choose layers to fine-tune"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91r2dk-7heJb"
      },
      "source": [
        "for i,v in enumerate(detection_model.trainable_variables):\n",
        "    print(f\"i: {i} \\t name: {v.name} \\t shape:{v.shape} \\t dtype={v.dtype}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6S9QjSWheJb"
      },
      "source": [
        "### select prediction layer variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDdvGRCYrkJt"
      },
      "source": [
        "to_fine_tune = []\n",
        "for v in detection_model.trainable_variables:\n",
        "  if v.name.startswith('WeightSharedConvolutionalBoxPredictor'):\n",
        "    to_fine_tune.append(v)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwzzGkzyrkJv"
      },
      "source": [
        "print(to_fine_tune[0].name)\n",
        "print(to_fine_tune[2].name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffvhZZu2rkJy"
      },
      "source": [
        "## train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qJcTJTvheJb"
      },
      "source": [
        "g_images_list = train_image_tensors[0:2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XifEma9DheJb"
      },
      "source": [
        "g_preprocessed_image = detection_model.preprocess(g_images_list[0])\n",
        "print(f\"g_preprocessed_image type: {type(g_preprocessed_image)}\")\n",
        "print(f\"g_preprocessed_image length: {len(g_preprocessed_image)}\")\n",
        "print(f\"index 0 has the preprocessed image of shape {g_preprocessed_image[0].shape}\")\n",
        "print(f\"index 1 has information about the image's true shape excluding padding: {g_preprocessed_image[1]}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXKZR5rOheJb"
      },
      "source": [
        "preprocessed_image_list = []\n",
        "true_shape_list = []\n",
        "\n",
        "for img in g_images_list:\n",
        "    processed_img, true_shape = detection_model.preprocess(img)\n",
        "    preprocessed_image_list.append(processed_img)\n",
        "    true_shape_list.append(true_shape)\n",
        "\n",
        "print(f\"preprocessed_image_list is of type {type(preprocessed_image_list)}\")\n",
        "print(f\"preprocessed_image_list has length {len(preprocessed_image_list)}\")\n",
        "print()\n",
        "print(f\"true_shape_list is of type {type(true_shape_list)}\")\n",
        "print(f\"true_shape_list has length {len(true_shape_list)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpyb8CyKheJb"
      },
      "source": [
        "## make prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "lines_to_next_cell": 2,
        "id": "5oAoT6q0heJb"
      },
      "source": [
        "# Try to call `predict` and pass in lists; look at the error message\n",
        "try:\n",
        "    detection_model.predict(preprocessed_image_list, true_shape_list)\n",
        "except AttributeError as e:\n",
        "    print(\"Error message:\", e)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "He2IbVteheJb"
      },
      "source": [
        "preprocessed_image_tensor = tf.concat(preprocessed_image_list, axis=0)\n",
        "true_shape_tensor = tf.concat(true_shape_list, axis=0)\n",
        "\n",
        "print(f\"preprocessed_image_tensor shape: {preprocessed_image_tensor.shape}\")\n",
        "print(f\"true_shape_tensor shape: {true_shape_tensor.shape}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSiOe-FFheJb"
      },
      "source": [
        "prediction_dict = detection_model.predict(preprocessed_image_tensor, true_shape_tensor)\n",
        "print(\"keys in prediction_dict:\")\n",
        "for key in prediction_dict.keys():\n",
        "    print(key)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amiRcKs8heJb"
      },
      "source": [
        "#### calculate loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPeDlc6VheJb"
      },
      "source": [
        "try:\n",
        "    losses_dict = detection_model.loss(prediction_dict, true_shape_tensor)\n",
        "except RuntimeError as e:\n",
        "    print(e)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XWjDnRxheJb"
      },
      "source": [
        "gt_boxes_list = gt_box_tensors[0:2]\n",
        "gt_classes_list = gt_classes_one_hot_tensors[0:2]\n",
        "detection_model.provide_groundtruth(groundtruth_boxes_list=gt_boxes_list, groundtruth_classes_list=gt_classes_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-bztzeNheJb"
      },
      "source": [
        "losses_dict = detection_model.loss(prediction_dict, true_shape_tensor)\n",
        "print(f\"loss dictionary keys: {losses_dict.keys()}\")\n",
        "print(f\"localization loss {losses_dict['Loss/localization_loss']:.8f}\")\n",
        "print(f\"classification loss {losses_dict['Loss/classification_loss']:.8f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdY8qHSLheJb"
      },
      "source": [
        "detection_model.provide_groundtruth(groundtruth_boxes_list=[], groundtruth_classes_list=[])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIUKsYPLheJb"
      },
      "source": [
        "## define training step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "lines_to_next_cell": 2,
        "id": "nttIf_ZgheJb"
      },
      "source": [
        "@tf.function\n",
        "def train_step_fn(image_list,\n",
        "                groundtruth_boxes_list,\n",
        "                groundtruth_classes_list,\n",
        "                model,\n",
        "                optimizer,\n",
        "                vars_to_fine_tune):\n",
        "    with tf.GradientTape() as tape:\n",
        "        preprocessed_image_list, true_shape_list = [], []\n",
        "        for img in image_list:\n",
        "          processed_img, true_shape = model.preprocess(img)\n",
        "          preprocessed_image_list.append(processed_img), true_shape_list.append(true_shape)\n",
        "        preprocessed_image_tensor = tf.concat(preprocessed_image_list, axis=0)\n",
        "        true_shape_tensor = tf.concat(true_shape_list, axis=0)\n",
        "        model.provide_groundtruth(groundtruth_boxes_list=groundtruth_boxes_list, groundtruth_classes_list=groundtruth_classes_list)\n",
        "        prediction_dict = model.predict(preprocessed_image_tensor, true_shape_tensor)\n",
        "        losses_dict = model.loss(prediction_dict, true_shape_tensor)\n",
        "        total_loss = losses_dict['Loss/localization_loss'] + losses_dict['Loss/classification_loss']\n",
        "        gradients = tape.gradient([total_loss], to_fine_tune)\n",
        "        optimizer.apply_gradients(zip(gradients, to_fine_tune))\n",
        "    return total_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9n7imaJRrkJ1"
      },
      "source": [
        "## training loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgpDQ3JbrkJ3"
      },
      "source": [
        "print('Start fine-tuning!', flush=True)\n",
        "for idx in range(num_batches):\n",
        "    all_keys = list(range(len(train_images_np)))\n",
        "    random.shuffle(all_keys)\n",
        "    example_keys = all_keys[:batch_size]\n",
        "    gt_boxes_list = [gt_box_tensors[key] for key in example_keys]\n",
        "    gt_classes_list = [gt_classes_one_hot_tensors[key] for key in example_keys]\n",
        "    image_tensors = [train_image_tensors[key] for key in example_keys]\n",
        "    total_loss = train_step_fn(image_tensors, \n",
        "                               gt_boxes_list, \n",
        "                               gt_classes_list,\n",
        "                               detection_model,\n",
        "                               optimizer,\n",
        "                               to_fine_tune\n",
        "                              )\n",
        "\n",
        "    if idx % 10 == 0:\n",
        "        print('batch ' + str(idx) + ' of ' + str(num_batches)\n",
        "        + ', loss=' +  str(total_loss.numpy()), flush=True)\n",
        "print('Done fine-tuning!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHlXL1x_Z3tc"
      },
      "source": [
        "### Load test images and run inference with new model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QL697_MnHcJF"
      },
      "source": [
        "!rm zombie-walk-frames.zip\n",
        "!rm -rf ./zombie-walk\n",
        "!rm -rf ./results\n",
        "\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/zombie-walk-frames.zip \\\n",
        "    -O zombie-walk-frames.zip\n",
        "\n",
        "local_zip = './zombie-walk-frames.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('./results')\n",
        "zip_ref.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_LJJ8wWhzlZ"
      },
      "source": [
        "### load images into numpy arrays to prepare it for inference."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcE6OwrHQJya"
      },
      "source": [
        "test_image_dir = './results/'\n",
        "test_images_np = []\n",
        "\n",
        "for i in range(0, 237):\n",
        "    image_path = os.path.join(test_image_dir, 'zombie-walk' + \"{0:04}\".format(i) + '.jpg')\n",
        "    print(image_path)\n",
        "    test_images_np.append(np.expand_dims(\n",
        "      load_image_into_numpy_array(image_path), axis=0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-GIbqkzrkJ_"
      },
      "source": [
        "### Preprocess, predict, and post process an image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aXt-bodrkKA"
      },
      "source": [
        "@tf.function\n",
        "def detect(input_tensor):\n",
        "    preprocessed_image, shapes = detection_model.preprocess(input_tensor)\n",
        "    prediction_dict = detection_model.predict(preprocessed_image, shapes)\n",
        "    detections = detection_model.postprocess(prediction_dict, shapes)    \n",
        "    return detections"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhXwX7O8rkKC"
      },
      "source": [
        "label_id_offset = 1\n",
        "results = {'boxes': [], 'scores': []}\n",
        "\n",
        "for i in range(len(test_images_np)):\n",
        "    input_tensor = tf.convert_to_tensor(test_images_np[i], dtype=tf.float32)\n",
        "    detections = detect(input_tensor)\n",
        "    plot_detections(\n",
        "      test_images_np[i][0],\n",
        "      detections['detection_boxes'][0].numpy(),\n",
        "      detections['detection_classes'][0].numpy().astype(np.uint32)\n",
        "      + label_id_offset,\n",
        "      detections['detection_scores'][0].numpy(),\n",
        "      category_index, figsize=(15, 20), image_name=\"./results/gif_frame_\" + ('%03d' % i) + \".jpg\")\n",
        "    results['boxes'].append(detections['detection_boxes'][0][0].numpy())\n",
        "    results['scores'].append(detections['detection_scores'][0][0].numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNV5uwN7rkKE"
      },
      "source": [
        "print(len(results['boxes']))\n",
        "print(results['boxes'][0].shape)\n",
        "print()\n",
        "\n",
        "print(np.allclose(results['boxes'][0], [0.28838485, 0.06830047, 0.7213766 , 0.19833465], rtol=0.18))\n",
        "print(np.allclose(results['boxes'][5], [0.29168868, 0.07529271, 0.72504973, 0.20099735], rtol=0.18))\n",
        "print(np.allclose(results['boxes'][10], [0.29548776, 0.07994056, 0.7238164 , 0.20778716], rtol=0.18))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDEYAkg3l4lh"
      },
      "source": [
        "x = np.array(results['scores'])\n",
        "\n",
        "zombie_detected = (np.where(x > 0.9, 1, 0).sum())/237*100\n",
        "print(zombie_detected)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ww0hLDI4fB1f"
      },
      "source": [
        "print('Frame 0')\n",
        "display(IPyImage('./results/gif_frame_000.jpg'))\n",
        "print()\n",
        "print('Frame 5')\n",
        "display(IPyImage('./results/gif_frame_005.jpg'))\n",
        "print()\n",
        "print('Frame 10')\n",
        "display(IPyImage('./results/gif_frame_010.jpg'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrjHwbkVXqLG"
      },
      "source": [
        "## Create a zip of the zombie-walk images. \n",
        "You can download this if you like to create your own animations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SeKSNOG7BVd4"
      },
      "source": [
        "zipf = zipfile.ZipFile('./zombie.zip', 'w', zipfile.ZIP_DEFLATED)\n",
        "\n",
        "filenames = glob.glob('./results/gif_frame_*.jpg')\n",
        "filenames = sorted(filenames)\n",
        "\n",
        "for filename in filenames:\n",
        "    zipf.write(filename)\n",
        "\n",
        "zipf.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTDH45KYX1Iv"
      },
      "source": [
        "## Create Zombie animation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RW1FrT2iNnpy"
      },
      "source": [
        "imageio.plugins.freeimage.download()\n",
        "\n",
        "!rm -rf ./results/zombie-anim.gif\n",
        "\n",
        "anim_file = './zombie-anim.gif'\n",
        "\n",
        "filenames = glob.glob('./results/gif_frame_*.jpg')\n",
        "filenames = sorted(filenames)\n",
        "last = -1\n",
        "images = []\n",
        "\n",
        "for filename in filenames:\n",
        "    image = imageio.imread(filename)\n",
        "    images.append(image)\n",
        "\n",
        "imageio.mimsave(anim_file, images, 'GIF-FI', fps=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JqLoPaigdl4"
      },
      "source": [
        "Unfortunately, using `IPyImage` in the notebook (as you've done in the rubber ducky detection tutorial) for the large `gif` generated will disconnect the runtime. To view the animation, you can instead use the `Files` pane on the left and double-click on `zombie-anim.gif`. That will open a preview page on the right. It will take 2 to 3 minutes to load and see the walking zombie."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdRXjK-xhTDA"
      },
      "source": [
        "## Save results file for grading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxx-hJlkhvNs"
      },
      "source": [
        "Run the cell below to save your results. Download the `results.data` file and upload it to the grader in the classroom."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0PbSjPXrkKN"
      },
      "source": [
        "import pickle\n",
        "\n",
        "# remove file if it exists\n",
        "!rm results.data\n",
        "\n",
        "# write results to binary file. upload for grading.\n",
        "with open('results.data', 'wb') as filehandle:\n",
        "    pickle.dump(results['boxes'], filehandle)\n",
        "\n",
        "print('Done saving! Please download `results.data` from the Files tab\\n' \\\n",
        "      'on the left and submit for grading.\\nYou can also use the next cell as a shortcut for downloading.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggdow2tKAACF"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('results.data')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcJHinV3nS1O"
      },
      "source": [
        "**Congratulations on completing this assignment! Please go back to the Coursera classroom and upload `results.data` to the Graded Lab item for Week 2.**"
      ]
    }
  ]
}